{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-Singh2309/Python2-Shivank/blob/main/09-Web_Scraping_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping"
      ],
      "metadata": {
        "id": "UhLYvqXUHE8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZlK8ajTKSPhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "- What is Web Scraping?\n",
        "- Understanding a website's structure (HTML/CSS)\n",
        "- Using `request` module\n",
        "- Using `beautiful soup` for scraping data\n",
        "- Fixing the data format"
      ],
      "metadata": {
        "id": "kuwIlgF4HLMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "BwM00g5cSWi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Web Scraping\n",
        "\n",
        "#### <u>What is Web Scraping?</u>\n",
        "Web scraping is a technique used to extract large amounts of data from websites. It involves programmatically visiting web pages and extracting information from them. This process can range from simple data collection tasks, like scraping prices from an e-commerce site, to more complex activities, such as harvesting contact information for research purposes.\n",
        "\n",
        "</br>\n",
        "\n",
        "#### <u>Is web scraping legal?</u>\n",
        "The legality of web scraping depends on several factors and can vary by country. Generally, scraping publicly accessible data for personal, non-commercial use is considered legal. However, issues arise when scraping:\n",
        "\n",
        "- Data behind a login or other access controls.\n",
        "- Copyrighted material or proprietary information.\n",
        "- Websites with explicit terms of service that prohibit scraping.\n",
        "\n",
        "It's crucial to respect privacy laws (like GDPR in Europe), adhere to the website's terms of service, and avoid overloading servers.\n",
        "\n",
        "When in doubt, seeking legal advice or obtaining explicit permission from the website owner is advisable."
      ],
      "metadata": {
        "id": "B_K1PHe4KMDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <u>How to make sure that whatever we are scraping is appropriate?</u>\n",
        "\n",
        "Websites often use a `robots.txt` file to communicate with web crawlers. Access this file by appending`/robots.txt` to the website's base URL (e.g., https://en.wikipedia.org/robots.txt).\n",
        "\n",
        "This file provides guidelines on what parts of the site can or can't be crawled by automated agents. However, note that `robots.txt` is more of a guideline for search engines and does not have legal standing.\n",
        "\n",
        "Most websites have a Terms of Service (ToS) or Terms of Use agreement, often found in the footer of the homepage. Review this document to see if it explicitly prohibits scraping."
      ],
      "metadata": {
        "id": "bF9NPDDMKcOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "BNfgn3z6rd7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding how web pages are structured and how we can extract data from them."
      ],
      "metadata": {
        "id": "56rQzjekLK6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/179/original/img1.png?1706078289\">"
      ],
      "metadata": {
        "id": "aX2KfIoeMkrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The web pages are developed using `HTML (Hyper Text Markup Language)`, where there are some pre-defined `tags` used to develop/design such pages. All tags start with `<>` and end as `</>`.\n",
        "\n",
        "For example, `<h1>` tag is used for writing heading and `<p>` tag is used for writing paragraphs.\n",
        "\n",
        "Knowing these tags is useful as it can help us to select which data to scape.\n",
        "\n",
        "Each tag has some special attributes like,\n",
        "- `class`\n",
        "  - Used to add some special properties to corresponding tag like styling, etc.\n",
        "  - Multiple tags can have same `class` attribute.\n",
        "- `id`\n",
        "  - Also used to add extra properties to tags but each tag can have a unique `id` attribute.\n",
        "\n",
        "We use such attributes to target specifc tags to extract data, like targetting all tags having some `class` attribute, etc.\n",
        "\n",
        "One more important thing to notice here is the hierarchy of tags, as in the above image some `tags(children)` are within another `tags(parent)`. This heirarchy is also useful for targetting certain tags."
      ],
      "metadata": {
        "id": "Dwpp4RPwPrr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "6cc8IF3BsQLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement:\n",
        "\n",
        "* We'll be scraping this website http://books.toscrape.com/index.html for collecting book data like, name of book, genre, price, reviews, etc.\n",
        "\n",
        "* Before scraping, it is recommended to check the website and understand it's structure, what data it has.\n",
        "\n",
        "* As per the current task, we have around 1000 books, distributed on multiple pages. We will scrape the data of all of books."
      ],
      "metadata": {
        "id": "uzVFAuCeTuGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "duTJrmFSuRtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting web content -\n",
        "\n",
        "We will be using the `requests` module here to fetch the content of webpage.\n",
        "\n",
        "Usually whenever we load some URL in browser it makes a `GET` request to that particular endpoint and then respected server responds with the HTML code for corresponding page.\n",
        "\n",
        "We can perform similar action with `requests.get()` function as it pings the URL and returns with the corresonding details."
      ],
      "metadata": {
        "id": "BMDjTm3RpL_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9hEDH2O8Bgb"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"http://books.toscrape.com/index.html\"\n",
        "home_page = requests.get(base_url)\n",
        "\n",
        "# checking whether the request made was successful or not\n",
        "if home_page.status_code == 200:\n",
        "  print(\"SUCCESS\")\n",
        "else:\n",
        "  print(f\"FAILED, status code: {home_page.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VXnLkhdXF2W",
        "outputId": "a76ecc09-66b4-4366-97f1-42afec6663ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Information about some common staus codes :\n",
        "\n",
        "1. **200 OK**: The request has been successfully processed, and the server returns the requested content.\n",
        "\n",
        "2. **404 Not Found**: The requested resource or page could not be found on the server.\n",
        "\n",
        "3. **403 Forbidden**: Access to the requested resource is forbidden or not allowed for the client.\n",
        "\n",
        "4. **500 Internal Server Error**: The server encountered an unexpected error while processing the request.\n",
        "\n",
        "5. **302 Found (or 301 Moved Permanently)**: The requested resource has been temporarily (or permanently) moved to a different URL, and the client should follow the redirection."
      ],
      "metadata": {
        "id": "H5eqNVOpNeMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/288/original/img1.png?1706109577\">"
      ],
      "metadata": {
        "id": "45yMjWg7D4GD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "bHoB8MkZtWi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting all books from a page -"
      ],
      "metadata": {
        "id": "z8hDLsDLG9nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the web content as HTML code, now we need to parse this code so that we can extract relevant information from it.\n",
        "\n",
        "One popular python module used for such task is `beautiful soup`. It can parse the web content and allows user to extract data from specific tags."
      ],
      "metadata": {
        "id": "ddMCQzPWp3GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "35zld8H5Xgce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(markup=home_page.content, parser=\"html.parser\")"
      ],
      "metadata": {
        "id": "4sbNMDV-brkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/289/original/img2.png?1706109628\">\n",
        "\n",
        "Now we will use the HTML tag information to extract data.\n",
        "\n",
        "Here we are extracting the section responsible for rendering book data onto the main page. As we can see in above image highlighted `<li>` tag is our target.\n",
        "\n",
        "And since there are 20 books per page so we can see multiple `<li>` tags one after another."
      ],
      "metadata": {
        "id": "b77OD7K9EGRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `soup.find_all` method to target the specific tag according to it's name, the class attribute it holds or even the id attribute if required.\n",
        "\n",
        "This will return the list of all the captured `<li>` tags."
      ],
      "metadata": {
        "id": "9stsamHoq5PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = soup.find_all(name=\"li\", class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
        "len(books)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVl9RiD3_8Jz",
        "outputId": "e7db3c8d-7d2f-4719-9e42-d07bf8e20e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful Soup (bs4) is a Python library designed for web scraping purposes to pull the data out of HTML and XML files. It creates parse trees that is helpful to extract the data easily. Here are some of the commonly used methods in Beautiful Soup:\n",
        "\n",
        "1. **find()**: This method is used to find the first tag that matches a given criteria. For example, `soup.find('div')` would find the first `div` tag in the HTML document. You can also pass attributes to refine the search, like `soup.find('div', class_='example')`.\n",
        "\n",
        "2. **find_all()**: Unlike `find()`, `find_all()` retrieves all tags that match the criteria. It's useful when you want to extract information from multiple tags of the same type. For example, `soup.find_all('a')` would return a list of all anchor tags in the document.\n",
        "\n",
        "3. **select()**: This method allows you to use CSS selectors to find elements in the document. It's particularly handy when dealing with classes or IDs. For instance, `soup.select('.someclass')` would find all elements with the class `someclass`.\n",
        "\n",
        "4. **select_one()**: Similar to `select()`, but instead of returning all matches, it only returns the first match. For example, `soup.select_one('#uniqueId')` would find the first element with the ID `uniqueId`.\n",
        "\n",
        "These methods are integral to navigating and parsing HTML/XML documents with Beautiful Soup, making it easier to scrape data from websites."
      ],
      "metadata": {
        "id": "h5zFkVyExU0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4LfHO8yRf_jC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting data of a single book -"
      ],
      "metadata": {
        "id": "yjHDQ7yCG6Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will go to the actual location of book where its data present and extract it into a dictionary."
      ],
      "metadata": {
        "id": "JJptW1S1rdCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book = books[0]"
      ],
      "metadata": {
        "id": "SmtOFzExAcDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/290/original/3.png?1706109693\">\n",
        "\n",
        "As we can see each book thumbnail holds the information of page URL where the data of corresponding book is present.\n",
        "\n",
        "First we are going to extract this URL by utilising the hierarchy of this web page.\n",
        "\n",
        "Basically the `<a>` tag holding the URL of a book is within the `<li>` tag of that book which we already extracted and as we learnt earlier this `<a>` tag is one of the children of `<li>` tag.\n",
        "\n",
        "Hence we can query on that book by using `.findChild()` method to target the `<a>` tag and then capture its URL by accessing the `href` attribute."
      ],
      "metadata": {
        "id": "-G76JDewEUWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_url = book.findChild(name=\"a\").get(\"href\")\n",
        "book_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VFpqZ-YoB4GG",
        "outputId": "522d8532-96a0-4fd2-c208-6ad808a02be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'catalogue/a-light-in-the-attic_1000/index.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ths issue is this is a relative URL which needs to be converted into complete absolute URL in order for us to access it using `requests.get()`.\n",
        "\n",
        "One way is directly prefixing `base_url` before this. The `urljoin` method from `urllib.parse` module is a very popular and error-free way to do so."
      ],
      "metadata": {
        "id": "n2golhY-sdqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urljoin"
      ],
      "metadata": {
        "id": "OKGFl_zzCVMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_url = urljoin(base_url, book_url)\n",
        "book_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BcVBsDqpDUoo",
        "outputId": "d23feca8-a117-49da-95a4-cfa8c44bfe67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what a page for book looks like, now we understand its structure and extract the data.\n",
        "\n",
        "Basically from this page we need data like **Name of book** and the **Product Information** table.\n",
        "\n",
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/291/original/4.png?1706109767\">\n",
        "\n",
        "We start by getting its HTML content using `requests` and parsing it via `beautiful soup`."
      ],
      "metadata": {
        "id": "B6r2kxpHElYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_info = requests.get(book_url).content\n",
        "book_soup = BeautifulSoup(markup=book_info, parser=\"html.parser\")"
      ],
      "metadata": {
        "id": "qH0bOt5dDemk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/292/original/5.png?1706110251\">\n",
        "\n",
        "So from the web structure, **Name of book** is within the only `<h1>` tag present in this page. Lets grab this first.\n",
        "\n",
        "We can use `.getText()` to get the text present between any tags."
      ],
      "metadata": {
        "id": "VyKPvwSpGcqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = book_soup.find(name=\"h1\").getText()\n",
        "name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xahCEx0oFGlm",
        "outputId": "1ddee3a0-ce36-4bda-9cd7-92a3050065a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A Light in the Attic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/063/293/original/6.png?1706110345\">\n",
        "\n",
        "Now, the **Product Information** table is structured as a HTML table, where each row data is between `<tr>` tags.\n",
        "\n",
        "And each `<tr>` tag holds the information of heading between `<th>` tag and corresponding value between `<td>` tag.\n",
        "\n",
        "So now, we get hold on all the rows and one by one extract the heading and their corresponding values."
      ],
      "metadata": {
        "id": "NHojSsR3Gyx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_table_data = book_soup.find_all(name=\"tr\")\n",
        "len(book_table_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTK_fN1qFb1a",
        "outputId": "b610221a-7d0b-4451-d439-ea7a0f20b049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_data = {}\n",
        "for row in book_table_data:\n",
        "  key = row.find(name=\"th\").getText()\n",
        "  value = row.find(name=\"td\").getText()\n",
        "  book_data[key] = value\n",
        "\n",
        "book_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TWWwwEtF72I",
        "outputId": "516c4429-f0e8-4381-dbfe-259da4da13b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'UPC': 'a897fe39b1053632',\n",
              " 'Product Type': 'Books',\n",
              " 'Price (excl. tax)': '£51.77',\n",
              " 'Price (incl. tax)': '£51.77',\n",
              " 'Tax': '£0.00',\n",
              " 'Availability': 'In stock (22 available)',\n",
              " 'Number of reviews': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's wrap all the functionality into one function, that takes the absolute URL of a particular book page and returns data in a dictionary."
      ],
      "metadata": {
        "id": "AxuzsjYJJs50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_book(book_url):\n",
        "  book_info = requests.get(book_url).content\n",
        "  book_soup = BeautifulSoup(markup=book_info, parser=\"html.parser\")\n",
        "\n",
        "  book_data = {}\n",
        "\n",
        "  # getting name\n",
        "  name = book_soup.find(name=\"h1\").getText()\n",
        "  book_data['name'] = name\n",
        "\n",
        "  # getting other data\n",
        "  book_table_data = book_soup.find_all(name=\"tr\")\n",
        "  for row in book_table_data:\n",
        "    key = row.find(name=\"th\").getText()\n",
        "    value = row.find(name=\"td\").getText()\n",
        "    book_data[key] = value\n",
        "\n",
        "  # let's also keep the url of book in final result\n",
        "  book_data['url'] = book_url\n",
        "  return book_data\n",
        "\n",
        "# let's test this\n",
        "scrape_book(book_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Lfe6EkJ3xZ",
        "outputId": "a3dcfe5c-20ae-42fa-8ca6-4eb6b70232bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'A Light in the Attic',\n",
              " 'UPC': 'a897fe39b1053632',\n",
              " 'Product Type': 'Books',\n",
              " 'Price (excl. tax)': '£51.77',\n",
              " 'Price (incl. tax)': '£51.77',\n",
              " 'Tax': '£0.00',\n",
              " 'Availability': 'In stock (22 available)',\n",
              " 'Number of reviews': '0',\n",
              " 'url': 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4SRaAqQzgpFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetching the data of all books in one page -"
      ],
      "metadata": {
        "id": "zRdUiI4EH9DN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the pattern of changes in URL with respect to page change.\n",
        "\n",
        "* So if we go to the base url in browser and open next page, we can see that our URL changes to `https://books.toscrape.com/catalogue/page-2.html`\n",
        "\n",
        "* And if we go to the third page, then our URL changes to `https://books.toscrape.com/catalogue/page-3.html`\n",
        "\n",
        "* From here we can formulate that the URL for `i-th` page will be `https://books.toscrape.com/catalogue/page-i.html`"
      ],
      "metadata": {
        "id": "wLi8_4ZDIO8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the data of all the books from the 1st page -\n",
        "\n",
        "page_url = \"https://books.toscrape.com/catalogue/page-i.html\"\n",
        "\n",
        "page_content = requests.get(page_url).content\n",
        "page_soup = BeautifulSoup(markup=page_content, parser=\"html.parser\")\n",
        "page_books = soup.find_all(name=\"li\", class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
        "\n",
        "print(len(page_books))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmlmP-SSL0Mi",
        "outputId": "33ea19bd-f267-4cfa-b017-e3b4ddc90e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since we are already have the function to scrape each book data, we can directly use it to scrape all the books present in one page and store it."
      ],
      "metadata": {
        "id": "wQYpa-ZhvXQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_data = []\n",
        "\n",
        "for book in page_books:\n",
        "  book_url = book.findChild(name=\"a\").get(\"href\")\n",
        "  # converting relative URL to absolute\n",
        "  book_url = urljoin(base_url, book_url)\n",
        "\n",
        "  book_data = scrape_book(book_url)\n",
        "  books_data.append(book_data)"
      ],
      "metadata": {
        "id": "qpQzXhaaH0bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDCV2KwTLO0i",
        "outputId": "9d792360-00f8-436f-b9b3-83d4ce0b22d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'A Light in the Attic',\n",
              "  'UPC': 'a897fe39b1053632',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£51.77',\n",
              "  'Price (incl. tax)': '£51.77',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (22 available)',\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'},\n",
              " {'name': 'Tipping the Velvet',\n",
              "  'UPC': '90fa61229261140a',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£53.74',\n",
              "  'Price (incl. tax)': '£53.74',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (20 available)',\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html'},\n",
              " {'name': 'Soumission',\n",
              "  'UPC': '6957f44c3847a760',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£50.10',\n",
              "  'Price (incl. tax)': '£50.10',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (20 available)',\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/soumission_998/index.html'}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's wrap that functionality into a function so that we can directly use it to scrape all the pages."
      ],
      "metadata": {
        "id": "Ye6B8wVILk57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_page(page_url):\n",
        "  books_data = []\n",
        "  page_content = requests.get(page_url).content\n",
        "  page_soup = BeautifulSoup(markup=page_content, parser=\"html.parser\")\n",
        "  page_books = soup.find_all(name=\"li\", class_=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\")\n",
        "\n",
        "  for book in books:\n",
        "    book_url = book.findChild(name=\"a\").get(\"href\")\n",
        "    book_url = urljoin(base_url, book_url)\n",
        "    book_data = scrape_book(book_url)\n",
        "    books_data.append(book_data)\n",
        "  return books_data"
      ],
      "metadata": {
        "id": "rmo5ewQ5LRrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zgyRcAMHi1z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scraping all books from all the pages -\n",
        "\n",
        "From the website we can see that there are total 50 pages, but sometimes this information is not given in the websites.\n",
        "\n",
        "That is why we'll use a generic approach here to keep extracting page data until all the pages are done.\n",
        "\n",
        "Let's try requesting the data from page 100, which is more than the total number of pages on our website."
      ],
      "metadata": {
        "id": "-XoX_IImMsAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get(\"https://books.toscrape.com/catalogue/page-100.html\").status_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCh9jZJFMmSc",
        "outputId": "d92163fd-52a1-4b0e-a329-c917b7d5fc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "404"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`404` status codes means that page does not exist.\n",
        "\n",
        "So our approach is to keep looking for pages till we get 404 and there we'll stop data scraping."
      ],
      "metadata": {
        "id": "7yH2wn5BNxaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page_count = 1\n",
        "data = []\n",
        "\n",
        "while True:\n",
        "  page_url = f\"https://books.toscrape.com/catalogue/page-{page_count}.html\"\n",
        "  status = requests.get(page_url).status_code\n",
        "\n",
        "  # break the loop if we exceed the total page count\n",
        "  if status == 404:\n",
        "    break\n",
        "\n",
        "  page_data = scrape_page(page_url)\n",
        "  data.extend(page_data) # do not use .append() since the function returns a list\n",
        "  print(f\"Page: {page_count} is SUCCESSFULLY scraped\")\n",
        "\n",
        "  page_count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAWOdtj1NF6O",
        "outputId": "2ac5d87c-8dbd-4971-9707-26b07b28b00f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: 1 is SUCCESSFULLY scraped\n",
            "Page: 2 is SUCCESSFULLY scraped\n",
            "Page: 3 is SUCCESSFULLY scraped\n",
            "Page: 4 is SUCCESSFULLY scraped\n",
            "Page: 5 is SUCCESSFULLY scraped\n",
            "Page: 6 is SUCCESSFULLY scraped\n",
            "Page: 7 is SUCCESSFULLY scraped\n",
            "Page: 8 is SUCCESSFULLY scraped\n",
            "Page: 9 is SUCCESSFULLY scraped\n",
            "Page: 10 is SUCCESSFULLY scraped\n",
            "Page: 11 is SUCCESSFULLY scraped\n",
            "Page: 12 is SUCCESSFULLY scraped\n",
            "Page: 13 is SUCCESSFULLY scraped\n",
            "Page: 14 is SUCCESSFULLY scraped\n",
            "Page: 15 is SUCCESSFULLY scraped\n",
            "Page: 16 is SUCCESSFULLY scraped\n",
            "Page: 17 is SUCCESSFULLY scraped\n",
            "Page: 18 is SUCCESSFULLY scraped\n",
            "Page: 19 is SUCCESSFULLY scraped\n",
            "Page: 20 is SUCCESSFULLY scraped\n",
            "Page: 21 is SUCCESSFULLY scraped\n",
            "Page: 22 is SUCCESSFULLY scraped\n",
            "Page: 23 is SUCCESSFULLY scraped\n",
            "Page: 24 is SUCCESSFULLY scraped\n",
            "Page: 25 is SUCCESSFULLY scraped\n",
            "Page: 26 is SUCCESSFULLY scraped\n",
            "Page: 27 is SUCCESSFULLY scraped\n",
            "Page: 28 is SUCCESSFULLY scraped\n",
            "Page: 29 is SUCCESSFULLY scraped\n",
            "Page: 30 is SUCCESSFULLY scraped\n",
            "Page: 31 is SUCCESSFULLY scraped\n",
            "Page: 32 is SUCCESSFULLY scraped\n",
            "Page: 33 is SUCCESSFULLY scraped\n",
            "Page: 34 is SUCCESSFULLY scraped\n",
            "Page: 35 is SUCCESSFULLY scraped\n",
            "Page: 36 is SUCCESSFULLY scraped\n",
            "Page: 37 is SUCCESSFULLY scraped\n",
            "Page: 38 is SUCCESSFULLY scraped\n",
            "Page: 39 is SUCCESSFULLY scraped\n",
            "Page: 40 is SUCCESSFULLY scraped\n",
            "Page: 41 is SUCCESSFULLY scraped\n",
            "Page: 42 is SUCCESSFULLY scraped\n",
            "Page: 43 is SUCCESSFULLY scraped\n",
            "Page: 44 is SUCCESSFULLY scraped\n",
            "Page: 45 is SUCCESSFULLY scraped\n",
            "Page: 46 is SUCCESSFULLY scraped\n",
            "Page: 47 is SUCCESSFULLY scraped\n",
            "Page: 48 is SUCCESSFULLY scraped\n",
            "Page: 49 is SUCCESSFULLY scraped\n",
            "Page: 50 is SUCCESSFULLY scraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** For the sake of this class, we'll only scrape 5 pages as scraping all 50 will take good amount of time."
      ],
      "metadata": {
        "id": "FrO79q2tPcjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page_count = 1\n",
        "data = []\n",
        "\n",
        "while True:\n",
        "  page_url = f\"https://books.toscrape.com/catalogue/page-{page_count}.html\"\n",
        "  status = requests.get(page_url).status_code\n",
        "\n",
        "  # break the loop if we exceed the total page count\n",
        "  if status == 404 or page_count == 6:\n",
        "    break\n",
        "\n",
        "  page_data = scrape_page(page_url)\n",
        "  data.extend(page_data) # do not use .append() since the function returns a list\n",
        "  print(f\"Page: {page_count} is SUCCESSFULLY scraped\")\n",
        "\n",
        "  page_count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S63EjN7uPATF",
        "outputId": "c2233bf1-cd56-4b8b-dec8-23ac1de2c4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: 1 is SUCCESSFULLY scraped\n",
            "Page: 2 is SUCCESSFULLY scraped\n",
            "Page: 3 is SUCCESSFULLY scraped\n",
            "Page: 4 is SUCCESSFULLY scraped\n",
            "Page: 5 is SUCCESSFULLY scraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5P2zQDvPo_F",
        "outputId": "e8a900b6-4f23-4f08-d8b1-c96f8d506772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'A Light in the Attic',\n",
              "  'UPC': 'a897fe39b1053632',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£51.77',\n",
              "  'Price (incl. tax)': '£51.77',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (22 available)',\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'},\n",
              " {'name': 'Tipping the Velvet',\n",
              "  'UPC': '90fa61229261140a',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': '£53.74',\n",
              "  'Price (incl. tax)': '£53.74',\n",
              "  'Tax': '£0.00',\n",
              "  'Availability': 'In stock (20 available)',\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html'}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "K49V_8-ljXaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixing the data formatting -\n",
        "\n",
        "The only issue now is that our data is not in a proper format.\n",
        "\n",
        "So in this section, we will fix those issues one by one."
      ],
      "metadata": {
        "id": "XmzL9PiaQfbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book = data[0].copy()\n",
        "book"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jybDDeW3QGTJ",
        "outputId": "b77ff859-17c5-4d67-a8fe-131fb0400ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'A Light in the Attic',\n",
              " 'UPC': 'a897fe39b1053632',\n",
              " 'Product Type': 'Books',\n",
              " 'Price (excl. tax)': '£51.77',\n",
              " 'Price (incl. tax)': '£51.77',\n",
              " 'Tax': '£0.00',\n",
              " 'Availability': 'In stock (22 available)',\n",
              " 'Number of reviews': '0',\n",
              " 'url': 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing £ symbol and converting it to float\n",
        "float(book['Price (excl. tax)'][1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj76EWbHRPsX",
        "outputId": "b06fcfc2-031c-492a-fdee-c33f9027e25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.77"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting 'availability' in 2 keys: 'quantity_available' and 'is_available'\n",
        "\n",
        "quantity_available = int(book['Availability'].split(\"(\")[-1][:-1].split()[0])\n",
        "is_available = book['Availability'].split(\"(\")[0].strip()\n",
        "\n",
        "quantity_available, is_available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-01IY_vsRiLY",
        "outputId": "2ea6fd01-194f-40a9-e93a-a45d4f2ba9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22, 'In stock')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix(item):\n",
        "  item['Price (excl. tax)'] = float(item['Price (excl. tax)'][1:])\n",
        "  item['Price (incl. tax)'] = float(item['Price (incl. tax)'][1:])\n",
        "  item['Tax'] = float(item['Tax'][1:])\n",
        "  availability = item.pop('Availability')\n",
        "  item['is_available'] = True if availability.split(\"(\")[0].strip() == 'In stock' else False\n",
        "  item['quantity_available'] = int(availability.split(\"(\")[-1][:-1].split()[0])\n",
        "  return item\n",
        "\n",
        "formatted_data = [fix(item.copy()) for item in data]"
      ],
      "metadata": {
        "id": "3LNnwvXeR9Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rodzIY6bmVr0",
        "outputId": "f1915a5b-9fa3-4397-8aa4-2961cfe2d2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'A Light in the Attic',\n",
              "  'UPC': 'a897fe39b1053632',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': 51.77,\n",
              "  'Price (incl. tax)': 51.77,\n",
              "  'Tax': 0.0,\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html',\n",
              "  'is_available': True,\n",
              "  'quantity_available': 22},\n",
              " {'name': 'Tipping the Velvet',\n",
              "  'UPC': '90fa61229261140a',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': 53.74,\n",
              "  'Price (incl. tax)': 53.74,\n",
              "  'Tax': 0.0,\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html',\n",
              "  'is_available': True,\n",
              "  'quantity_available': 20},\n",
              " {'name': 'Soumission',\n",
              "  'UPC': '6957f44c3847a760',\n",
              "  'Product Type': 'Books',\n",
              "  'Price (excl. tax)': 50.1,\n",
              "  'Price (incl. tax)': 50.1,\n",
              "  'Tax': 0.0,\n",
              "  'Number of reviews': '0',\n",
              "  'url': 'http://books.toscrape.com/catalogue/soumission_998/index.html',\n",
              "  'is_available': True,\n",
              "  'quantity_available': 20}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have well formatted data scraped from the website."
      ],
      "metadata": {
        "id": "sw4wV-bxoBb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "v2xJMTmwkLoY"
      }
    }
  ]
}